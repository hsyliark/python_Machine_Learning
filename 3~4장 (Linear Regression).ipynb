{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# need library\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# warning remove\n",
    "if type(tf.contrib) != type(tf):\n",
    "    tf.contrib._warning = None\n",
    "# 딥러닝 구동에 필요한 케라스 함수\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y^ =  2.3 x +  79.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = [2,4,6,8]\n",
    "y = [81,93,91,97]\n",
    "\n",
    "mx = np.mean(x)\n",
    "my = np.mean(y)\n",
    "\n",
    "divisor = sum([(mx - i)**2 for i in x])\n",
    "\n",
    "def top(x, mx, y, my):\n",
    "    d = 0\n",
    "    for i in range(len(x)):\n",
    "        d += (x[i] - mx) * (y[i] - my)\n",
    "    return d\n",
    "dividend = top(x, mx, y, my)\n",
    "\n",
    "w = dividend / divisor # 딥러닝에서는 보통 기울기를 weight의 첫글자를 따서 w로 표현함\n",
    "b = my - (w * mx)\n",
    "\n",
    "print('y^ = ', w, 'x + ', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE(Root Mean Squared Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공부한 시간=2, 실제 점수=81, 예측 점수=82\n",
      "공부한 시간=4, 실제 점수=93, 예측 점수=88\n",
      "공부한 시간=6, 실제 점수=91, 예측 점수=94\n",
      "공부한 시간=8, 실제 점수=97, 예측 점수=100\n",
      "RMSE 최종값: 3.3166247903554\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ab = [3, 76] # 임의의 기울기와 y절편\n",
    "\n",
    "data = [[2,81],[4,93],[6,91],[8,97]]\n",
    "x = [i[0] for i in data]\n",
    "y = [i[1] for i in data]\n",
    "\n",
    "def predict(x):\n",
    "    return ab[0] * x + ab[1]\n",
    "\n",
    "def rmse(p, a):\n",
    "    return np.sqrt(((p - a)**2).mean())\n",
    "    \n",
    "def rmse_val(predict_result, y):\n",
    "    return rmse(np.array(predict_result), np.array(y))\n",
    "\n",
    "predict_result = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    predict_result.append(predict(x[i]))\n",
    "    print(\"공부한 시간=%.f, 실제 점수=%.f, 예측 점수=%.f\" % (x[i], y[i], predict(x[i])))\n",
    "    \n",
    "print(\"RMSE 최종값: \" + str(rmse_val(predict_result,y)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Algorithm (경사하강법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, RMSE = 30.2139, w = 7.5235, b = 80.5984\n",
      "Epoch: 100, RMSE = 2.8860, w = 2.2299, b = 79.4181\n",
      "Epoch: 200, RMSE = 2.8826, w = 2.2601, b = 79.2379\n",
      "Epoch: 300, RMSE = 2.8815, w = 2.2773, b = 79.1353\n",
      "Epoch: 400, RMSE = 2.8811, w = 2.2871, b = 79.0770\n",
      "Epoch: 500, RMSE = 2.8810, w = 2.2927, b = 79.0438\n",
      "Epoch: 600, RMSE = 2.8810, w = 2.2958, b = 79.0249\n",
      "Epoch: 700, RMSE = 2.8810, w = 2.2976, b = 79.0142\n",
      "Epoch: 800, RMSE = 2.8810, w = 2.2987, b = 79.0081\n",
      "Epoch: 900, RMSE = 2.8810, w = 2.2992, b = 79.0046\n",
      "Epoch: 1000, RMSE = 2.8810, w = 2.2996, b = 79.0026\n",
      "Epoch: 1100, RMSE = 2.8810, w = 2.2998, b = 79.0015\n",
      "Epoch: 1200, RMSE = 2.8810, w = 2.2999, b = 79.0008\n",
      "Epoch: 1300, RMSE = 2.8810, w = 2.2999, b = 79.0005\n",
      "Epoch: 1400, RMSE = 2.8810, w = 2.3000, b = 79.0003\n",
      "Epoch: 1500, RMSE = 2.8810, w = 2.3000, b = 79.0002\n",
      "Epoch: 1600, RMSE = 2.8810, w = 2.3000, b = 79.0001\n",
      "Epoch: 1700, RMSE = 2.8810, w = 2.3000, b = 79.0001\n",
      "Epoch: 1800, RMSE = 2.8810, w = 2.3000, b = 79.0000\n",
      "Epoch: 1900, RMSE = 2.8810, w = 2.3000, b = 79.0000\n",
      "Epoch: 2000, RMSE = 2.8810, w = 2.3000, b = 79.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "data = [[2,81],[4,93],[6,91],[8,97]]\n",
    "x_data = [i[0] for i in data]\n",
    "y_data = [i[1] for i in data]\n",
    "\n",
    "learning_rate = 0.1 # 학습률 (경사하강법 구현 시 중요한 parameter)\n",
    "\n",
    "# 임의의 기울가와 y절편 생성\n",
    "w = tf.Variable(tf.random_uniform([1], 0, 10, dtype = tf.float64, seed = 0))\n",
    "b = tf.Variable(tf.random_uniform([1], 0, 100, dtype = tf.float64, seed = 0)) \n",
    "\n",
    "y = w * x_data + b\n",
    "\n",
    "# RMSE(Root Mean Squared Error)\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square( y - y_data )))\n",
    "\n",
    "# RMSE를 최소로 하는 경우 찾기\n",
    "gradient_descent = tf.train.GradientDescentOptimizer(learning_rate).minimize(rmse)\n",
    "\n",
    "# 결과값 출력\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) # 변수 초기화\n",
    "    # 2001번 실행\n",
    "    for step in range(2001):\n",
    "        sess.run(gradient_descent)\n",
    "        # 100번마다 결과 출력\n",
    "        if step % 100 == 0:\n",
    "            print(\"Epoch: %.f, RMSE = %.04f, w = %.4f, b = %.4f\" % (step,sess.run(rmse),sess.run(w),sess.run(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, RMSE = 49.1842, w1 = 7.5270, w2 = 7.8160, b = 80.5980\n",
      "Epoch: 100, RMSE = 1.8368, w1 = 1.1306, w2 = 2.1316, b = 78.5119\n",
      "Epoch: 200, RMSE = 1.8370, w1 = 1.1879, w2 = 2.1487, b = 78.1057\n",
      "Epoch: 300, RMSE = 1.8370, w1 = 1.2122, w2 = 2.1571, b = 77.9352\n",
      "Epoch: 400, RMSE = 1.8370, w1 = 1.2226, w2 = 2.1607, b = 77.8636\n",
      "Epoch: 500, RMSE = 1.8370, w1 = 1.2269, w2 = 2.1622, b = 77.8335\n",
      "Epoch: 600, RMSE = 1.8370, w1 = 1.2288, w2 = 2.1628, b = 77.8208\n",
      "Epoch: 700, RMSE = 1.8370, w1 = 1.2295, w2 = 2.1631, b = 77.8155\n",
      "Epoch: 800, RMSE = 1.8370, w1 = 1.2299, w2 = 2.1632, b = 77.8133\n",
      "Epoch: 900, RMSE = 1.8370, w1 = 1.2300, w2 = 2.1632, b = 77.8124\n",
      "Epoch: 1000, RMSE = 1.8370, w1 = 1.2301, w2 = 2.1633, b = 77.8120\n",
      "Epoch: 1100, RMSE = 1.8370, w1 = 1.2301, w2 = 2.1633, b = 77.8118\n",
      "Epoch: 1200, RMSE = 1.8370, w1 = 1.2301, w2 = 2.1633, b = 77.8117\n",
      "Epoch: 1300, RMSE = 1.8370, w1 = 1.2301, w2 = 2.1633, b = 77.8117\n",
      "Epoch: 1400, RMSE = 1.8370, w1 = 1.2301, w2 = 2.1633, b = 77.8117\n",
      "Epoch: 1500, RMSE = 1.8370, w1 = 1.2301, w2 = 2.1633, b = 77.8117\n",
      "Epoch: 1600, RMSE = 1.8370, w1 = 1.2301, w2 = 2.1633, b = 77.8117\n",
      "Epoch: 1700, RMSE = 1.8370, w1 = 1.2301, w2 = 2.1633, b = 77.8117\n",
      "Epoch: 1800, RMSE = 1.8370, w1 = 1.2301, w2 = 2.1633, b = 77.8117\n",
      "Epoch: 1900, RMSE = 1.8370, w1 = 1.2301, w2 = 2.1633, b = 77.8117\n",
      "Epoch: 2000, RMSE = 1.8370, w1 = 1.2301, w2 = 2.1633, b = 77.8117\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "data = [[2,0,81],[4,4,93],[6,2,91],[8,3,97]]\n",
    "x1 = [i[0] for i in data]\n",
    "x2 = [i[1] for i in data]\n",
    "y_data = [i[2] for i in data]\n",
    "\n",
    "w1 = tf.Variable(tf.random_uniform([1], 0, 10, dtype=tf.float64, seed=0))\n",
    "w2 = tf.Variable(tf.random_uniform([1], 0, 10, dtype=tf.float64, seed=0))\n",
    "b = tf.Variable(tf.random_uniform([1], 0, 100, dtype=tf.float64, seed=0))\n",
    "\n",
    "y = w1 * x1 + w2 * x2 + b\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "# RMSE(Root Mean Squared Error)\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square( y - y_data )))\n",
    "\n",
    "# RMSE를 최소로 하는 경우 찾기\n",
    "gradient_descent = tf.train.GradientDescentOptimizer(learning_rate).minimize(rmse)\n",
    "\n",
    "# 결과값 출력\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) # 변수 초기화\n",
    "    # 2001번 실행\n",
    "    for step in range(2001):\n",
    "        sess.run(gradient_descent)\n",
    "        # 100번마다 결과 출력\n",
    "        if step % 100 == 0:\n",
    "            print(\"Epoch: %.f, RMSE = %.04f, w1 = %.4f, w2 = %.4f, b = %.4f\" % (step,sess.run(rmse),sess.run(w1),sess.run(w2),sess.run(b)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
