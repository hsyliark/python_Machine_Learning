{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# need library\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# warning remove\n",
    "if type(tf.contrib) != type(tf):\n",
    "    tf.contrib._warning = None\n",
    "# 딥러닝 구동에 필요한 케라스 함수\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y^ =  2.3 x +  79.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = [2,4,6,8]\n",
    "y = [81,93,91,97]\n",
    "\n",
    "mx = np.mean(x)\n",
    "my = np.mean(y)\n",
    "\n",
    "divisor = sum([(mx - i)**2 for i in x])\n",
    "\n",
    "def top(x, mx, y, my):\n",
    "    d = 0\n",
    "    for i in range(len(x)):\n",
    "        d += (x[i] - mx) * (y[i] - my)\n",
    "    return d\n",
    "dividend = top(x, mx, y, my)\n",
    "\n",
    "w = dividend / divisor # 딥러닝에서는 보통 기울기를 weight의 첫글자를 따서 w로 표현함\n",
    "b = my - (w * mx)\n",
    "\n",
    "print('y^ = ', w, 'x + ', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE(Root Mean Squared Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공부한 시간=2, 실제 점수=81, 예측 점수=82\n",
      "공부한 시간=4, 실제 점수=93, 예측 점수=88\n",
      "공부한 시간=6, 실제 점수=91, 예측 점수=94\n",
      "공부한 시간=8, 실제 점수=97, 예측 점수=100\n",
      "RMSE 최종값: 3.3166247903554\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ab = [3, 76] # 임의의 기울기와 y절편\n",
    "\n",
    "data = [[2,81],[4,93],[6,91],[8,97]]\n",
    "x = [i[0] for i in data]\n",
    "y = [i[1] for i in data]\n",
    "\n",
    "def predict(x):\n",
    "    return ab[0] * x + ab[1]\n",
    "\n",
    "def rmse(p, a):\n",
    "    return np.sqrt(((p - a)**2).mean())\n",
    "    \n",
    "def rmse_val(predict_result, y):\n",
    "    return rmse(np.array(predict_result), np.array(y))\n",
    "\n",
    "predict_result = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    predict_result.append(predict(x[i]))\n",
    "    print(\"공부한 시간=%.f, 실제 점수=%.f, 예측 점수=%.f\" % (x[i], y[i], predict(x[i])))\n",
    "    \n",
    "print(\"RMSE 최종값: \" + str(rmse_val(predict_result,y)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Algorithm (경사하강법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, RMSE = 30.2139, w = 7.5235, b = 80.5984\n",
      "Epoch: 100, RMSE = 2.8860, w = 2.2299, b = 79.4181\n",
      "Epoch: 200, RMSE = 2.8826, w = 2.2601, b = 79.2379\n",
      "Epoch: 300, RMSE = 2.8815, w = 2.2773, b = 79.1353\n",
      "Epoch: 400, RMSE = 2.8811, w = 2.2871, b = 79.0770\n",
      "Epoch: 500, RMSE = 2.8810, w = 2.2927, b = 79.0438\n",
      "Epoch: 600, RMSE = 2.8810, w = 2.2958, b = 79.0249\n",
      "Epoch: 700, RMSE = 2.8810, w = 2.2976, b = 79.0142\n",
      "Epoch: 800, RMSE = 2.8810, w = 2.2987, b = 79.0081\n",
      "Epoch: 900, RMSE = 2.8810, w = 2.2992, b = 79.0046\n",
      "Epoch: 1000, RMSE = 2.8810, w = 2.2996, b = 79.0026\n",
      "Epoch: 1100, RMSE = 2.8810, w = 2.2998, b = 79.0015\n",
      "Epoch: 1200, RMSE = 2.8810, w = 2.2999, b = 79.0008\n",
      "Epoch: 1300, RMSE = 2.8810, w = 2.2999, b = 79.0005\n",
      "Epoch: 1400, RMSE = 2.8810, w = 2.3000, b = 79.0003\n",
      "Epoch: 1500, RMSE = 2.8810, w = 2.3000, b = 79.0002\n",
      "Epoch: 1600, RMSE = 2.8810, w = 2.3000, b = 79.0001\n",
      "Epoch: 1700, RMSE = 2.8810, w = 2.3000, b = 79.0001\n",
      "Epoch: 1800, RMSE = 2.8810, w = 2.3000, b = 79.0000\n",
      "Epoch: 1900, RMSE = 2.8810, w = 2.3000, b = 79.0000\n",
      "Epoch: 2000, RMSE = 2.8810, w = 2.3000, b = 79.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "data = [[2,81],[4,93],[6,91],[8,97]]\n",
    "x_data = [i[0] for i in data]\n",
    "y_data = [i[1] for i in data]\n",
    "\n",
    "learning_rate = 0.1 # 학습률 (경사하강법 구현 시 중요한 parameter)\n",
    "\n",
    "# 임의의 기울기와 y절편 생성\n",
    "w = tf.Variable(tf.random_uniform([1], 0, 10, dtype = tf.float64, seed = 0))\n",
    "b = tf.Variable(tf.random_uniform([1], 0, 100, dtype = tf.float64, seed = 0)) \n",
    "\n",
    "y = w * x_data + b\n",
    "\n",
    "# RMSE(Root Mean Squared Error)\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square( y - y_data )))\n",
    "\n",
    "# RMSE를 최소로 하는 경우 찾기\n",
    "gradient_descent = tf.train.GradientDescentOptimizer(learning_rate).minimize(rmse)\n",
    "\n",
    "# 결과값 출력\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) # 변수 초기화\n",
    "    # 2001번 실행\n",
    "    for step in range(2001):\n",
    "        sess.run(gradient_descent)\n",
    "        # 100번마다 결과 출력\n",
    "        if step % 100 == 0:\n",
    "            print(\"Epoch: %.f, RMSE = %.04f, w = %.4f, b = %.4f\" % (step,sess.run(rmse),sess.run(w),sess.run(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, RMSE = 30.8346, w1 = 8.3122, w2 = 8.1632, b = 8.1449\n",
      "Epoch: 100, RMSE = 26.4997, w1 = 10.1463, w2 = 7.5455, b = 12.3662\n",
      "Epoch: 200, RMSE = 24.8433, w1 = 9.9388, w2 = 6.5410, b = 16.3031\n",
      "Epoch: 300, RMSE = 23.2302, w1 = 9.5919, w2 = 5.8431, b = 20.2424\n",
      "Epoch: 400, RMSE = 21.6344, w1 = 9.1540, w2 = 5.3456, b = 24.1815\n",
      "Epoch: 500, RMSE = 20.0452, w1 = 8.6587, w2 = 4.9751, b = 28.1196\n",
      "Epoch: 600, RMSE = 18.4582, w1 = 8.1284, w2 = 4.6819, b = 32.0569\n",
      "Epoch: 700, RMSE = 16.8721, w1 = 7.5777, w2 = 4.4341, b = 35.9935\n",
      "Epoch: 800, RMSE = 15.2862, w1 = 7.0155, w2 = 4.2116, b = 39.9296\n",
      "Epoch: 900, RMSE = 13.7005, w1 = 6.4474, w2 = 4.0024, b = 43.8655\n",
      "Epoch: 1000, RMSE = 12.1149, w1 = 5.8764, w2 = 3.7997, b = 47.8010\n",
      "Epoch: 1100, RMSE = 10.5295, w1 = 5.3040, w2 = 3.6000, b = 51.7363\n",
      "Epoch: 1200, RMSE = 8.9445, w1 = 4.7312, w2 = 3.4016, b = 55.6711\n",
      "Epoch: 1300, RMSE = 7.3599, w1 = 4.1583, w2 = 3.2036, b = 59.6053\n",
      "Epoch: 1400, RMSE = 5.7763, w1 = 3.5855, w2 = 3.0058, b = 63.5383\n",
      "Epoch: 1500, RMSE = 4.1948, w1 = 3.0130, w2 = 2.8081, b = 67.4689\n",
      "Epoch: 1600, RMSE = 2.6188, w1 = 2.4416, w2 = 2.6108, b = 71.3925\n",
      "Epoch: 1700, RMSE = 1.0730, w1 = 1.8756, w2 = 2.4154, b = 75.2785\n",
      "Epoch: 1800, RMSE = 1.8366, w1 = 1.3818, w2 = 2.2164, b = 76.8175\n",
      "Epoch: 1900, RMSE = 1.8369, w1 = 1.2922, w2 = 2.1848, b = 77.3938\n",
      "Epoch: 2000, RMSE = 1.8370, w1 = 1.2559, w2 = 2.1722, b = 77.6361\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "data = [[2,0,81],[4,4,93],[6,2,91],[8,3,97]]\n",
    "x1 = [i[0] for i in data]\n",
    "x2 = [i[1] for i in data]\n",
    "y_data = [i[2] for i in data]\n",
    "\n",
    "w1 = tf.Variable(tf.random_uniform([1], 0, 10, dtype=tf.float64, seed=0))\n",
    "w2 = tf.Variable(tf.random_uniform([1], 0, 10, dtype=tf.float64, seed=0))\n",
    "b = tf.Variable(tf.random_uniform([1], 0, 10, dtype=tf.float64, seed=0))\n",
    "\n",
    "y = w1 * x1 + w2 * x2 + b\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "# RMSE(Root Mean Squared Error)\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square( y - y_data )))\n",
    "\n",
    "# RMSE를 최소로 하는 경우 찾기\n",
    "gradient_descent = tf.train.GradientDescentOptimizer(learning_rate).minimize(rmse)\n",
    "\n",
    "# 결과값 출력\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) # 변수 초기화\n",
    "    # 2001번 실행\n",
    "    for step in range(2001):\n",
    "        sess.run(gradient_descent)\n",
    "        # 100번마다 결과 출력\n",
    "        if step % 100 == 0:\n",
    "            print(\"Epoch: %.f, RMSE = %.04f, w1 = %.4f, w2 = %.4f, b = %.4f\" % (step,sess.run(rmse),sess.run(w1),sess.run(w2),sess.run(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
